{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ZWxySdJNF5Xp"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from matplotlib import pyplot as plt\n",
    "from torchsummary import summary\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TC3VJHyKXcY-",
    "outputId": "0de04987-70e5-44d5-d962-72459029cd00"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# # CNN Encoder\n",
    "# class CNNEncoder(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(CNNEncoder, self).__init__()\n",
    "#         self.encoder = nn.Sequential(\n",
    "#             nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2),\n",
    "#             nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2),\n",
    "#             nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2),\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.encoder(x)\n",
    "\n",
    "# # summary(CNNEncoder().to(device), (1, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-3alU8TRXwbp",
    "outputId": "bbf455f9-4b3a-4b42-ad57-9b47a343ca82"
   },
   "outputs": [],
   "source": [
    "# # Dilated Residual Network (DRN)\n",
    "# class DRN(nn.Module):\n",
    "#     def __init__(self, dilation):\n",
    "#         super(DRN, self).__init__()\n",
    "#         self.conv = nn.Conv2d(256, 256, kernel_size=3, padding=dilation, dilation=dilation)\n",
    "#         self.relu = nn.ReLU()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         l1 = self.relu(self.conv(x))\n",
    "#         l2 = self.relu(self.conv(l1))\n",
    "#         return self.relu(self.conv(l2) + x)  # Residual connection\n",
    "\n",
    "# # summary(DRN(1).to(device), (256, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VARANy7Dh0Rl",
    "outputId": "f53a0a66-e725-43ae-c7b9-be976b74fac1"
   },
   "outputs": [],
   "source": [
    "# # Efficient Channel Attention (ECA)\n",
    "# class ECA(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(ECA, self).__init__()\n",
    "#         self.conv = nn.Conv2d(256, 256, kernel_size=1)\n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return x * self.sigmoid(self.conv(x))\n",
    "\n",
    "# summary(ECA().to(device), (256, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vsALc4GM6TTY",
    "outputId": "71636ede-6f4e-4624-fd9a-95d0b80c8d41"
   },
   "outputs": [],
   "source": [
    "# # Simple UNet\n",
    "# class UNet(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(UNet, self).__init__()\n",
    "\n",
    "#         self.encoder = nn.Sequential(\n",
    "#             nn.Conv2d(256, 128, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2),\n",
    "#             nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2),\n",
    "#             nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.MaxPool2d(2),\n",
    "#         )\n",
    "\n",
    "#         self.decoder = nn.Sequential(\n",
    "#             nn.ConvTranspose2d(64, 32, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Upsample(scale_factor=2),\n",
    "#             nn.ConvTranspose2d(32, 32, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Upsample(scale_factor=2),\n",
    "#             nn.ConvTranspose2d(32, 16, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Upsample(scale_factor=2),\n",
    "#             nn.ConvTranspose2d(16, 16, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Upsample(scale_factor=2),\n",
    "#             nn.Upsample(scale_factor=2),\n",
    "#             nn.ConvTranspose2d(16, 1, kernel_size=3, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Upsample(scale_factor=2),\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.encoder(x)\n",
    "#         return self.decoder(x)\n",
    "\n",
    "# summary(UNet().to(device), (256, 32, 32))\n",
    "\n",
    "# # Complete Model\n",
    "# class SARDespecklingNet(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(SARDespecklingNet, self).__init__()\n",
    "#         self.encoder = CNNEncoder()\n",
    "#         self.drn1 = DRN(dilation=1)\n",
    "#         self.drn3 = DRN(dilation=3)\n",
    "#         self.drn5 = DRN(dilation=5)\n",
    "#         self.eca = ECA()\n",
    "#         self.unet = UNet()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.encoder(x)\n",
    "#         x1 = self.drn1(x)\n",
    "#         x3 = self.drn3(x)\n",
    "#         x5 = self.drn5(x)\n",
    "#         x = self.eca(x1 + x3 + x5)\n",
    "#         return self.unet(x)\n",
    "\n",
    "# summary(SARDespecklingNet().to(device), (1, 256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "7sLNaANZEpDl"
   },
   "outputs": [],
   "source": [
    "# Dataset Placeholder (Assuming we have SAR Images & Clean Images)\n",
    "def prepare_data(n):\n",
    "    infiles = sorted(glob.glob('./s1/*.png'))[:n]\n",
    "    outfiles = sorted(glob.glob('./s2/*.png'))[:n]\n",
    "    in_data = []\n",
    "    out_data = []\n",
    "\n",
    "    for fi in infiles:\n",
    "        img = cv2.imread(fi)\n",
    "        img = cv2.resize(img, (256,256))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        in_data.append(img)\n",
    "\n",
    "    for fo in outfiles:\n",
    "        img = cv2.imread(fo)\n",
    "        img = cv2.resize(img, (256,256))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        out_data.append(img)\n",
    "    return in_data, out_data\n",
    "    \n",
    "class SARDataset(Dataset):\n",
    "    def __init__(self, sar_images, clean_images, transform=None):\n",
    "        self.sar_images = sar_images\n",
    "        self.clean_images = clean_images\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sar_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sar = self.sar_images[idx]\n",
    "        clean = self.clean_images[idx]\n",
    "        # Remove or modify the transform application\n",
    "        # if self.transform:\n",
    "        #     sar = self.transform(sar)\n",
    "        #     clean = self.transform(clean)\n",
    "        return sar, clean\n",
    "\n",
    "\n",
    "\n",
    "# Sample Data Preparation (Dummy Tensors)\n",
    "dummy_sar, clean_sar = prepare_data(1000) # Corresponding clean images\n",
    "dummy_sar = [np.array(img, dtype=np.float32) / 255 for img in dummy_sar]\n",
    "clean_sar = [np.array(img, dtype=np.float32) / 255 for img in clean_sar]\n",
    "dummy_sar = np.array(dummy_sar).reshape(-1, 1, 256, 256)\n",
    "clean_sar = np.array(clean_sar).reshape(-1, 1, 256, 256)\n",
    "\n",
    "# dummy_sar = dummy_sar.to(device)\n",
    "# clean_sar = clean_sar.to(device)\n",
    "\n",
    "# Remove the ToTensor transform or replace with a different transform if needed\n",
    "# transform = transforms.ToTensor()\n",
    "\n",
    "dataset = SARDataset(dummy_sar, clean_sar) #, transform=transform)\n",
    "train_loader = DataLoader(dataset, batch_size=10, shuffle=True)\n",
    "val_loader = DataLoader(dataset, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "3GfCQz-EQi_r"
   },
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL __main__.SARDespecklingNet was not an allowed global by default. Please use `torch.serialization.add_safe_globals([SARDespecklingNet])` or the `torch.serialization.safe_globals([SARDespecklingNet])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnpicklingError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m np.array(dummy_sar).shape\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m model = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./sar_model.pth\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\Project\\SAR Despeckling\\sarenv\\Lib\\site-packages\\torch\\serialization.py:1470\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1462\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[32m   1463\u001b[39m                     opened_zipfile,\n\u001b[32m   1464\u001b[39m                     map_location,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1467\u001b[39m                     **pickle_load_args,\n\u001b[32m   1468\u001b[39m                 )\n\u001b[32m   1469\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m pickle.UnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m1470\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle.UnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1471\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _load(\n\u001b[32m   1472\u001b[39m             opened_zipfile,\n\u001b[32m   1473\u001b[39m             map_location,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1476\u001b[39m             **pickle_load_args,\n\u001b[32m   1477\u001b[39m         )\n\u001b[32m   1478\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n",
      "\u001b[31mUnpicklingError\u001b[39m: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL __main__.SARDespecklingNet was not an allowed global by default. Please use `torch.serialization.add_safe_globals([SARDespecklingNet])` or the `torch.serialization.safe_globals([SARDespecklingNet])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html."
     ]
    }
   ],
   "source": [
    "np.array(dummy_sar).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "id": "pRSzo70DEfXl",
    "outputId": "ae49e876-544b-4ea6-e5af-f679f9a4387a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Training Loss: 0.03426116056740284\n"
     ]
    }
   ],
   "source": [
    "# Training and Evaluation\n",
    "def train_and_evaluate(model, train_loader, val_loader, epochs=10, lr=0.001):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    criterion = nn.MSELoss().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "\n",
    "        # print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))\n",
    "        for sar, clean in train_loader:\n",
    "            sar, clean = sar.float().to(device), clean.float().to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(sar)\n",
    "            loss = criterion(output, clean)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Training Loss: {train_loss/len(train_loader)}\")\n",
    "        \n",
    "        if (epoch%2 == 0):\n",
    "            torch.save(model, \"./sar_model.pth\")\n",
    "            \n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for sar, clean in val_loader:\n",
    "                sar, clean = sar.to(device, non_blocking=True), clean.to(device, non_blocking=True)\n",
    "                output = model(sar)\n",
    "                loss = criterion(output, clean)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        print(f\"Validation Loss: {val_loss/len(val_loader)}\")\n",
    "\n",
    "\n",
    "# Train the model\n",
    "# model = SARDespecklingNet()\n",
    "model = torch.load(\"./sar_model.pth\", weights_only=False)\n",
    "train_and_evaluate(model, train_loader, val_loader, epochs=10, lr=0.0001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.from_numpy(dummy_sar[:10]).float().to(device)\n",
    "# x = x.reshape(1, -1, 256, 256)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.load(\"./sar_model.pth\", weights_only=False)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    p = model(x).to(device)\n",
    "\n",
    "print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(p[2].reshape(256, 256))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
